services:
  ollama-pull-service:
    build:
      context: .
    container_name: ollama-pull
    command: >
      /bin/bash -c "
      echo 'Baixando modelos...';
      ollama serve && ollama pull llama3 && ollama pull nomic-embed-text && touch /app/models_ready.txt;
      echo 'Modelos baixados com sucesso.'"

  vector-store-service:
    build:
      context: .
      args:
        FAISS_VERSION: cpu  # Especifique 'gpu' se necessÃ¡rio
    container_name: vector-store-container
    volumes:
      - .:/app
    environment:
      - PYTHONUNBUFFERED=1
    depends_on:
      - ollama-pull-service
    command: >
      /bin/bash -c "
      while [ ! -f /app/models_ready.txt ]; do
        echo 'Aguardando o download dos modelos...';
        sleep 5;
      done;
      echo 'Modelos prontos, iniciando Vector Store...';
      python test/test.py"

networks:
  default:
    driver: bridge
